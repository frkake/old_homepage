---
layout: post
title: (R-CNN) Rich feature hierarchies for accurate object detection and semantic segmentation, CVPR, 2014
created: 2021-07-24 04:08:08
# updated: 2021-07-23 17:53:39
tags:
- object detection
- 2-stage
- SVM
- Selective Search
---

R-CNNについて今更勉強しました。　　
![]({{site.baseurl}}/images/2021-07-24-03-53-46.png)

## 概要

[`pdf`](https://arxiv.org/abs/1311.2524) [`code(caffe)`](https://github.com/rbgirshick/rcnn)

R-CNNは、CNNを物体検出に取り込んだ先駆け論文として広く知られているモデルです。
従来の方法では、スライディングウィンドウで、超大な数の領域をあらかた提案してCNNに突っ込んで学習するような方法が考えられてきました。しかし、それだと探索範囲が広すぎるため、より効率的に物体らしい領域を提案する必要がありました。R-CNNは[Selective Search](https://ivi.fnwi.uva.nl/isis/publications/bibtexbrowser.php?key=UijlingsIJCV2013&bib=all.bib)を利用して、効率的に領域提案を行い、CNNが実行可能な程度に効率化を図ったモデルです。  

R-CNNの実行手順は以下の流れになります。

1. Selective Searchを使った領域提案
2. 1. で提案された領域を入力画像から切り出し
3. 切り出した領域を一定サイズにワープ
4. ワープした画像をCNNに入力
5. 複数のSVMでクラス分類、bbox回帰を行う。

もう少し詳しく解説します。

### Selective Searchによる領域提案

まず、1. でR-CNNではSelective Searchを利用した領域提案を行っています。Selective Searchでは、次の手順で領域提案を行います。解説はかなりの部分を[しこあんさんのブログ](https://blog.shikoan.com/selective-search-rcnn/)をベースとしています。

1. Felzenszwalb法による画像のセグメンテーションを行い、各セグメントを一つの領域候補とする。
2. 各領域候補の色とテクスチャのヒストグラム特徴量を作成する。
3. 各領域同士で重なりのあるセグメントの組み合わせをNeighborとして全列挙する。
4. 2. の特徴量を使い、3. の全ての組み合わせから領域候補の類似度を計算。類似度計算には、下記の4項目を利用する。
      1. 色（2. で計算済みのRGBのヒストグラム特徴量）
      2. テクスチャ(2. で計算済みのLocal Binary Pattern(LBP)のヒストグラム特徴量)
      3. サイズ
      4. オーバーラップ度合い
5. 4. での類似度が高いもの同士をマージする。（Hierarical Search）

LBPは、エッジの情報がロバストに抽出できる手法として知られています。グレースケール化後、注目ピクセルの周囲に対して自身よりも値が、大きい（--> 1）小さい（--> 0）かのバイナリ値を作成した後に、真上から反時計回りに並べた2進数を出力します。  

![]({{site.baseurl}}/images/2021-07-24-03-37-54.png)
[こちらの記事](https://qiita.com/tancoro/items/959ae9c14048c06bea8e)より作成

![]({{site.baseurl}}/images/2021-07-24-03-24-41.png)

このLBP特徴画像とRGBの各チャネルに対して2. でヒストグラム特徴量を求めます。そして、隣接するセグメント同士でヒストグラム特徴量同士の類似度を計算して、再帰的に類似度が高いセグメントを結合していきます。セグメントと書いていますが、実際にはセグメントを囲む提案領域の矩形をマージしています。
これにより、Selective Searchによる領域提案を行います。  
テスト時には2000個程度の領域が提案されます。

### 特徴抽出/クラス分類

Selective Searchによって提案された領域は元画像からクロップされて一定サイズにワープされます。論文中では、特徴抽出にはAlexNetが使われているので、227x227サイズのRGB画像にリサイズされて、4096次元の特徴ベクトルが各提案領域について出力されます。具体的には5つのConv層と2つのFC層を通過します。FC層が挟まっているのもあって、固定サイズにリサイズしなければいけません。

こうして提案領域のCNN特徴量は、複数のSVMを使ってクラススコアを計算し、各クラスで独立にNMSさせて結果を出力します。SVMは一緒に学習するのではなく、各クラスで事前学習したものを利用します。  
てっきりbbox回帰モジュールがあると思っていましたが、無かったので意外でした。  

## 感想

* Faster R-CNNよりは需要低いけど、古典的アルゴからCNNベースへの橋渡し的な位置づけの論文だと思うので、抑えておくのは重要だと感じた。
* bbox回帰が後段に入っていないのは意外だった。
* 複数SVMをクラス分類に利用していて、かつ事前学習しなければいけないのはかなり面倒だし計算コストも高いと感じた。
